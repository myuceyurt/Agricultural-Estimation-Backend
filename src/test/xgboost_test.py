import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np
import xgboost as xgb # XGBoost kÃ¼tÃ¼phanesini iÃ§e aktarÄ±yoruz

# --- 1. VERÄ° YÃœKLEME VE HAZIRLAMA (Orijinal kod ile aynÄ±) ---
FILE_PATH = 'data/processed/final_training_data.csv'

df = pd.read_csv(FILE_PATH)
print("âœ… Veri baÅŸarÄ±yla DataFrame olarak okundu.\n")

df = df.dropna(subset=['verim_ton_hektar'])
X = df.drop(columns=['nnokta_id', 'verim_ton_hektar'])
y = df['verim_ton_hektar']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"EÄŸitim seti boyutu: {len(X_train)} satÄ±r")
print(f"Test seti boyutu: {len(X_test)} satÄ±r\n")

# --- 2. MODELÄ° OLUÅTURMA (XGBOOST) ---
# Not: XGBoost (aÄŸaÃ§ tabanlÄ± modeller) iÃ§in veri Ã¶lÃ§eklendirme (StandardScaler)
# genellikle GEREKLÄ° DEÄÄ°LDÄ°R. Bu adÄ±mÄ± atlÄ±yoruz.

# XGBoost Regresyon modelini tanÄ±mlÄ±yoruz.
# Random Forest'taki gibi temel parametreleri belirleyelim.
# objective='reg:squarederror': Regresyon iÃ§in standart kayÄ±p fonksiyonu (RMSE'yi minimize eder).
xgb_model = xgb.XGBRegressor(
    n_estimators=100,       # AÄŸaÃ§ sayÄ±sÄ± (RF'deki gibi)
    learning_rate=0.1,      # Ã–ÄŸrenme oranÄ± (daha dÃ¼ÅŸÃ¼k deÄŸerler daha saÄŸlam ama yavaÅŸ olabilir)
    max_depth=5,            # Her bir aÄŸacÄ±n maksimum derinliÄŸi
    random_state=42,
    objective='reg:squarederror' 
)

# --- 3. MODELÄ° EÄÄ°TME ---
print("ğŸ§  XGBoost Modeli eÄŸitiliyor...")
# Modeli, Ã¶lÃ§eklendirilmemiÅŸ orijinal X_train ve y_train verileriyle eÄŸitiyoruz
xgb_model.fit(X_train, y_train)
print("âœ… Model baÅŸarÄ±yla eÄŸitildi.\n")


# --- 4. TAHMÄ°N VE DEÄERLENDÄ°RME ---
print("âš™ï¸  Daha Ã¶nce gÃ¶rÃ¼lmemiÅŸ test verileriyle tahmin yapÄ±lÄ±yor...")
# Tahmin yaparken orijinal X_test'i kullanÄ±rÄ±z
y_pred = xgb_model.predict(X_test)

# Metrikleri hesaplama (Orijinal kod ile aynÄ±)
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print("--- MODEL PERFORMANS SONUÃ‡LARI (XGBOOST) ---")
print(f"R-Kare (RÂ²) Skoru: {r2:.4f}")
print(f"KÃ¶k Ortalama Kare Hata (RMSE): {rmse:.4f}\n")


# --- 5. YORUMLAMA (Orijinal kod ile aynÄ±) ---
print("--- YORUM ---")
if r2 < 0.5:
    print(f"Modelin RÂ² skoru ({r2:.2f}) oldukÃ§a dÃ¼ÅŸÃ¼k. Bu, girdilerle verim arasÄ±nda gÃ¼Ã§lÃ¼ bir iliÅŸki kuramadÄ±ÄŸÄ±nÄ± gÃ¶steriyor.")
    print(f"Tahminler, ortalama olarak gerÃ§ek deÄŸerden {rmse:.2f} ton/hektar kadar sapÄ±yor.")
    print("OlasÄ± nedenler: Veri setindeki satÄ±r sayÄ±sÄ±nÄ±n az olmasÄ± veya girdilerin verimi aÃ§Ä±klamak iÃ§in yeterli olmamasÄ±.")
elif r2 < 0.75:
    print(f"Modelin RÂ² skoru ({r2:.2f}) orta seviyede. Model, verimdeki deÄŸiÅŸkenliÄŸin bir kÄ±smÄ±nÄ± aÃ§Ä±klamayÄ± baÅŸarmÄ±ÅŸ.")
    print(f"Tahminler, ortalama olarak gerÃ§ek deÄŸerden {rmse:.2f} ton/hektar kadar sapÄ±yor.")
    print("Daha fazla veri ve daha Ã§eÅŸitli Ã¶zellikler (toprak, fenoloji) ekleyerek performans artÄ±rÄ±labilir.")
else:
    print(f"Modelin RÂ² skoru ({r2:.2f}) gayet iyi! Model, verimdeki deÄŸiÅŸkenliÄŸin Ã¶nemli bir kÄ±smÄ±nÄ± aÃ§Ä±klamayÄ± baÅŸarmÄ±ÅŸ.")
    print(f"Tahminler, ortalama olarak gerÃ§ek deÄŸerden {rmse:.2f} ton/hektar kadar sapÄ±yor.")
    print("Bu prototip, daha fazla veriyle Ã§ok daha gÃ¼Ã§lÃ¼ bir modelin temelini oluÅŸturabilir.")

# Tahmin detaylarÄ± (Orijinal kod ile aynÄ±)
print("\n--- TEST SETÄ° TAHMÄ°N DETAYLARI ---")
test_sonuclari = pd.DataFrame({'GerÃ§ek Verim': y_test, 'Tahmin Edilen Verim': y_pred})
test_sonuclari['Fark'] = test_sonuclari['GerÃ§ek Verim'] - test_sonuclari['Tahmin Edilen Verim']
print(test_sonuclari.to_string())